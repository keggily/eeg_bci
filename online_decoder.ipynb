{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n"
     ]
    }
   ],
   "source": [
    "from pylsl import StreamInlet, resolve_stream\n",
    "import numpy as np\n",
    "import joblib  # Used for loading sklearn models\n",
    "import sys\n",
    "import os\n",
    "\n",
    "sys.path.append('./src/processing')\n",
    "from preprocessing import *\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_dir = './models/'\n",
    "\n",
    "# Configuration\n",
    "srate = 160  #Sampling rate of the EEG data, adjust as needed\n",
    "epoch_length_sec = 5  # Length of the desired sample in seconds\n",
    "samples_needed = srate * epoch_length_sec  # Number of samples needed for ~5 seconds\n",
    "#manually from eegbci dataset\n",
    "channel_names = ['FC5', 'FC3', 'FC1', 'FCz', 'FC2', 'FC4', 'FC6', 'C5', 'C3', 'C1', 'Cz', 'C2', 'C4', 'C6', 'CP5', 'CP3', 'CP1', 'CPz', 'CP2', 'CP4', 'CP6', 'Fp1', 'Fpz', 'Fp2', 'AF7', 'AF3', 'AFz', 'AF4', 'AF8', 'F7', 'F5', 'F3', 'F1', 'Fz', 'F2', 'F4', 'F6', 'F8', 'FT7', 'FT8', 'T7', 'T8', 'T9', 'T10', 'TP7', 'TP8', 'P7', 'P5', 'P3', 'P1', 'Pz', 'P2', 'P4', 'P6', 'P8', 'PO7', 'PO3', 'POz', 'PO4', 'PO8', 'O1', 'Oz', 'O2', 'Iz']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(\"Looking for an EEG stream...\")\n",
    "streams = resolve_stream('type', 'EEG')\n",
    "\n",
    "inlet = StreamInlet(streams[0])\n",
    "\n",
    "def collect_and_save_single_sample(inlet, samples_needed):\n",
    "    buffer = []  # Initialize the buffer to hold collected samples\n",
    "    timestamps = []  # To store timestamps of each sample\n",
    "\n",
    "    while len(buffer) < samples_needed:\n",
    "        # Continuously pull samples\n",
    "        sample, timestamp = inlet.pull_sample()\n",
    "        if sample:\n",
    "            buffer.append(sample)  # Add the sample to the buffer\n",
    "            timestamps.append(timestamp)  # Add the timestamp\n",
    "\n",
    "        if len(buffer) >= samples_needed:\n",
    "            # Once we have enough samples, save and exit\n",
    "            np.save('sample.npy', np.array(buffer))  # Save the buffer as a numpy file\n",
    "            print(f\"Saved ~{epoch_length_sec}-second sample with {len(buffer)} samples.\")\n",
    "            return  # Exit the function, effectively stopping data collection\n",
    "\n",
    "# Call the function to collect, save, and then stop\n",
    "collect_and_save_single_sample(inlet, samples_needed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(800, 64)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # Test with one saved sample sent \n",
    "sample = np.load('sample.npy')\n",
    "sample.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating RawArray with float64 data, n_channels=64, n_times=800\n",
      "    Range : 0 ... 799 =      0.000 ...     4.994 secs\n",
      "Ready.\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 7 - 30 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 7.00\n",
      "- Lower transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 6.00 Hz)\n",
      "- Upper passband edge: 30.00 Hz\n",
      "- Upper transition bandwidth: 7.50 Hz (-6 dB cutoff frequency: 33.75 Hz)\n",
      "- Filter length: 265 samples (1.656 s)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.0s\n"
     ]
    }
   ],
   "source": [
    "preprocessed_data = preprocess_single_trial(sample, srate, channel_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save the preprocessed data\n",
    "np.save('preprocessed_data.npy', preprocessed_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# csp + lda decode\n",
    "model_path = os.path.join(models_dir, 'csp_lda.pkl')\n",
    "loaded_model = joblib.load(model_path)\n",
    "predicted_labels = loaded_model.predict(preprocessed_data)\n",
    "predicted_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# csp + logistic regression decode\n",
    "model_path = os.path.join(models_dir, 'csp_logistic.pkl')\n",
    "loaded_model = joblib.load(model_path)\n",
    "predicted_labels = loaded_model.predict(preprocessed_data)\n",
    "predicted_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# csp + svm decode\n",
    "model_path = os.path.join(models_dir, 'csp_svm.pkl')\n",
    "loaded_model = joblib.load(model_path)\n",
    "predicted_labels = loaded_model.predict(preprocessed_data)\n",
    "predicted_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "local\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "sys.path.append('./models')\n",
    "\n",
    "from eegconformer import EEGConformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, n_chans, n_times = preprocessed_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W NNPACK.cpp:64] Could not initialize NNPACK! Reason: Unsupported hardware.\n",
      "/Users/nana/Documents/GitHub/eeg/./models/base.py:180: UserWarning: LogSoftmax final layer will be removed! Please adjust your loss function accordingly (e.g. CrossEntropyLoss)!\n",
      "  warnings.warn(\"LogSoftmax final layer will be removed! \" +\n"
     ]
    }
   ],
   "source": [
    "# eeg_conformer decode\n",
    "model = EEGConformer(\n",
    "    n_outputs= 2,\n",
    "    n_chans = n_chans,\n",
    "    sfreq= srate,\n",
    "    n_times = n_times,\n",
    "    n_filters_time=40, \n",
    "    filter_time_length=25,\n",
    "    pool_time_length=75,\n",
    "    pool_time_stride=15,\n",
    "    drop_prob=0.7,\n",
    "    att_depth=3,\n",
    "    att_heads=10,\n",
    "    att_drop_prob=0.7,\n",
    "    final_fc_length='auto', # could be 'auto' or int\n",
    "    return_features=False, # returns the features before the last classification layer if True\n",
    "    chs_info=None,\n",
    "    input_window_seconds=None,\n",
    "    add_log_softmax=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model = os.path.join(models_dir, 'best_model.pth')\n",
    "checkpoint = torch.load(loaded_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "#model_path = 'path/to/your/saved/model.joblib'  # Path to your trained model\n",
    "srate = 160  # Sampling rate of the EEG data\n",
    "epoch_length_sec = 5  # Length of an epoch in seconds\n",
    "samples_per_epoch = srate * epoch_length_sec  # Number of samples per epoch\n",
    "\n",
    "# Load your model\n",
    "#model = joblib.load(model_path)\n",
    "\n",
    "# Resolve the stream\n",
    "print(\"Looking for an EEG stream...\")\n",
    "streams = resolve_stream('type', 'EEG', 'name', 'BioSemi')\n",
    "inlet = StreamInlet(streams[0])\n",
    "\n",
    "# Initialize a buffer for accumulating samples\n",
    "buffer = []\n",
    "\n",
    "def decode(epoch):\n",
    "    \"\"\"\n",
    "    Process and decode an epoch of EEG data.\n",
    "    \"\"\"\n",
    "    # Assuming you have defined preprocess_data and extract_features functions\n",
    "    preprocessed_epoch = preprocess_data(epoch)  # Preprocess the epoch\n",
    "    features = extract_features(preprocessed_epoch)  # Extract features\n",
    "    prediction = model.predict([features])  # Sklearn expects a 2D array for the features\n",
    "    return prediction\n",
    "\n",
    "def preprocess_data(epoch):\n",
    "    # Placeholder for your preprocessing steps\n",
    "    return epoch  # Return the processed epoch\n",
    "\n",
    "def extract_features(epoch):\n",
    "    # Placeholder for your feature extraction logic\n",
    "    return epoch.mean(axis=0) \n",
    "\n",
    "while True:\n",
    "    # Pull sample from LSL stream\n",
    "    sample, timestamp = inlet.pull_sample()\n",
    "    buffer.append(sample)\n",
    "    \n",
    "    # Check if buffer has enough samples to form an epoch\n",
    "    if len(buffer) >= samples_per_epoch:\n",
    "        epoch = np.array(buffer[:samples_per_epoch])  \n",
    "        buffer = buffer[samples_per_epoch:]  \n",
    "        \n",
    "        # Decode the epoch\n",
    "        prediction = decode(epoch)\n",
    "        print(f\"Timestamp: {timestamp}, Prediction: {prediction}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "eeg_decoder",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
