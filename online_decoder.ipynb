{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "local\n"
     ]
    }
   ],
   "source": [
    "from pylsl import StreamInlet, resolve_stream\n",
    "import numpy as np\n",
    "import joblib  # Used for loading sklearn models\n",
    "import sys\n",
    "import os\n",
    "#import torch\n",
    "\n",
    "sys.path.append('./src/processing')\n",
    "from preprocessing import *\n",
    "\n",
    "sys.path.append('./models')\n",
    "from eegconformer import EEGConformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_dir = './models/trained/'\n",
    "results_dir = './results/'\n",
    "\n",
    "# Configuration\n",
    "srate = 160  #Sampling rate of the EEG data\n",
    "epoch_length_sec = 5  # Length of the desired sample in seconds\n",
    "samples_needed = srate * epoch_length_sec  # Number of samples needed for ~5 seconds\n",
    "# Manually define from eegbci dataset\n",
    "channel_names = ['FC5', 'FC3', 'FC1', 'FCz', 'FC2', 'FC4', 'FC6', 'C5', 'C3', 'C1', 'Cz', 'C2', 'C4', 'C6', 'CP5', 'CP3', 'CP1', 'CPz', 'CP2', 'CP4', 'CP6', 'Fp1', 'Fpz', 'Fp2', 'AF7', 'AF3', 'AFz', 'AF4', 'AF8', 'F7', 'F5', 'F3', 'F1', 'Fz', 'F2', 'F4', 'F6', 'F8', 'FT7', 'FT8', 'T7', 'T8', 'T9', 'T10', 'TP7', 'TP8', 'P7', 'P5', 'P3', 'P1', 'Pz', 'P2', 'P4', 'P6', 'P8', 'PO7', 'PO3', 'POz', 'PO4', 'PO8', 'O1', 'Oz', 'O2', 'Iz']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking for an EEG stream...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-13 00:04:41.361 (   4.929s) [            9D67]      netinterfaces.cpp:91    INFO| netif 'lo0' (status: 1, multicast: 32768, broadcast: 0)\n",
      "2024-03-13 00:04:41.361 (   4.929s) [            9D67]      netinterfaces.cpp:91    INFO| netif 'lo0' (status: 1, multicast: 32768, broadcast: 0)\n",
      "2024-03-13 00:04:41.361 (   4.929s) [            9D67]      netinterfaces.cpp:102   INFO| \tIPv4 addr: 7f000001\n",
      "2024-03-13 00:04:41.361 (   4.929s) [            9D67]      netinterfaces.cpp:91    INFO| netif 'lo0' (status: 1, multicast: 32768, broadcast: 0)\n",
      "2024-03-13 00:04:41.361 (   4.929s) [            9D67]      netinterfaces.cpp:105   INFO| \tIPv6 addr: ::1\n",
      "2024-03-13 00:04:41.361 (   4.929s) [            9D67]      netinterfaces.cpp:91    INFO| netif 'lo0' (status: 1, multicast: 32768, broadcast: 0)\n",
      "2024-03-13 00:04:41.361 (   4.929s) [            9D67]      netinterfaces.cpp:105   INFO| \tIPv6 addr: fe80::1%lo0\n",
      "2024-03-13 00:04:41.361 (   4.929s) [            9D67]      netinterfaces.cpp:91    INFO| netif 'gif0' (status: 0, multicast: 32768, broadcast: 0)\n",
      "2024-03-13 00:04:41.361 (   4.929s) [            9D67]      netinterfaces.cpp:91    INFO| netif 'stf0' (status: 0, multicast: 0, broadcast: 0)\n",
      "2024-03-13 00:04:41.361 (   4.929s) [            9D67]      netinterfaces.cpp:91    INFO| netif 'anpi0' (status: 1, multicast: 32768, broadcast: 2)\n",
      "2024-03-13 00:04:41.361 (   4.929s) [            9D67]      netinterfaces.cpp:91    INFO| netif 'anpi0' (status: 1, multicast: 32768, broadcast: 2)\n",
      "2024-03-13 00:04:41.361 (   4.929s) [            9D67]      netinterfaces.cpp:105   INFO| \tIPv6 addr: fe80::4ce7:caff:fee0:5123%anpi0\n",
      "2024-03-13 00:04:41.361 (   4.929s) [            9D67]      netinterfaces.cpp:91    INFO| netif 'anpi1' (status: 1, multicast: 32768, broadcast: 2)\n",
      "2024-03-13 00:04:41.361 (   4.929s) [            9D67]      netinterfaces.cpp:91    INFO| netif 'anpi1' (status: 1, multicast: 32768, broadcast: 2)\n",
      "2024-03-13 00:04:41.361 (   4.929s) [            9D67]      netinterfaces.cpp:105   INFO| \tIPv6 addr: fe80::4ce7:caff:fee0:5124%anpi1\n",
      "2024-03-13 00:04:41.361 (   4.929s) [            9D67]      netinterfaces.cpp:91    INFO| netif 'en3' (status: 1, multicast: 32768, broadcast: 2)\n",
      "2024-03-13 00:04:41.361 (   4.929s) [            9D67]      netinterfaces.cpp:91    INFO| netif 'en4' (status: 1, multicast: 32768, broadcast: 2)\n",
      "2024-03-13 00:04:41.361 (   4.929s) [            9D67]      netinterfaces.cpp:91    INFO| netif 'en1' (status: 1, multicast: 32768, broadcast: 2)\n",
      "2024-03-13 00:04:41.361 (   4.929s) [            9D67]      netinterfaces.cpp:91    INFO| netif 'en2' (status: 1, multicast: 32768, broadcast: 2)\n",
      "2024-03-13 00:04:41.361 (   4.929s) [            9D67]      netinterfaces.cpp:91    INFO| netif 'ap1' (status: 0, multicast: 32768, broadcast: 2)\n",
      "2024-03-13 00:04:41.361 (   4.929s) [            9D67]      netinterfaces.cpp:91    INFO| netif 'en0' (status: 1, multicast: 32768, broadcast: 2)\n",
      "2024-03-13 00:04:41.361 (   4.929s) [            9D67]      netinterfaces.cpp:91    INFO| netif 'en0' (status: 1, multicast: 32768, broadcast: 2)\n",
      "2024-03-13 00:04:41.361 (   4.929s) [            9D67]      netinterfaces.cpp:105   INFO| \tIPv6 addr: fe80::424:b738:a47d:e6c6%en0\n",
      "2024-03-13 00:04:41.361 (   4.929s) [            9D67]      netinterfaces.cpp:91    INFO| netif 'en0' (status: 1, multicast: 32768, broadcast: 2)\n",
      "2024-03-13 00:04:41.361 (   4.929s) [            9D67]      netinterfaces.cpp:102   INFO| \tIPv4 addr: a0951a0\n",
      "2024-03-13 00:04:41.361 (   4.929s) [            9D67]      netinterfaces.cpp:91    INFO| netif 'bridge0' (status: 1, multicast: 32768, broadcast: 2)\n",
      "2024-03-13 00:04:41.361 (   4.929s) [            9D67]      netinterfaces.cpp:91    INFO| netif 'awdl0' (status: 1, multicast: 32768, broadcast: 2)\n",
      "2024-03-13 00:04:41.361 (   4.929s) [            9D67]      netinterfaces.cpp:91    INFO| netif 'awdl0' (status: 1, multicast: 32768, broadcast: 2)\n",
      "2024-03-13 00:04:41.361 (   4.929s) [            9D67]      netinterfaces.cpp:105   INFO| \tIPv6 addr: fe80::30fa:16ff:fe7e:b862%awdl0\n",
      "2024-03-13 00:04:41.361 (   4.929s) [            9D67]      netinterfaces.cpp:91    INFO| netif 'llw0' (status: 1, multicast: 32768, broadcast: 2)\n",
      "2024-03-13 00:04:41.361 (   4.929s) [            9D67]      netinterfaces.cpp:91    INFO| netif 'llw0' (status: 1, multicast: 32768, broadcast: 2)\n",
      "2024-03-13 00:04:41.361 (   4.929s) [            9D67]      netinterfaces.cpp:105   INFO| \tIPv6 addr: fe80::30fa:16ff:fe7e:b862%llw0\n",
      "2024-03-13 00:04:41.361 (   4.929s) [            9D67]      netinterfaces.cpp:91    INFO| netif 'utun0' (status: 1, multicast: 32768, broadcast: 0)\n",
      "2024-03-13 00:04:41.361 (   4.929s) [            9D67]      netinterfaces.cpp:91    INFO| netif 'utun0' (status: 1, multicast: 32768, broadcast: 0)\n",
      "2024-03-13 00:04:41.361 (   4.929s) [            9D67]      netinterfaces.cpp:105   INFO| \tIPv6 addr: fe80::c53a:6b43:d3f8:651d%utun0\n",
      "2024-03-13 00:04:41.361 (   4.929s) [            9D67]      netinterfaces.cpp:91    INFO| netif 'utun1' (status: 1, multicast: 32768, broadcast: 0)\n",
      "2024-03-13 00:04:41.361 (   4.929s) [            9D67]      netinterfaces.cpp:91    INFO| netif 'utun1' (status: 1, multicast: 32768, broadcast: 0)\n",
      "2024-03-13 00:04:41.361 (   4.929s) [            9D67]      netinterfaces.cpp:105   INFO| \tIPv6 addr: fe80::7083:cfb1:12c1:6f74%utun1\n",
      "2024-03-13 00:04:41.361 (   4.930s) [            9D67]      netinterfaces.cpp:91    INFO| netif 'utun2' (status: 1, multicast: 32768, broadcast: 0)\n",
      "2024-03-13 00:04:41.361 (   4.930s) [            9D67]      netinterfaces.cpp:91    INFO| netif 'utun2' (status: 1, multicast: 32768, broadcast: 0)\n",
      "2024-03-13 00:04:41.362 (   4.930s) [            9D67]      netinterfaces.cpp:105   INFO| \tIPv6 addr: fe80::ce81:b1c:bd2c:69e%utun2\n",
      "2024-03-13 00:04:41.362 (   4.930s) [            9D67]      netinterfaces.cpp:91    INFO| netif 'utun3' (status: 1, multicast: 32768, broadcast: 0)\n",
      "2024-03-13 00:04:41.362 (   4.930s) [            9D67]      netinterfaces.cpp:91    INFO| netif 'utun3' (status: 1, multicast: 32768, broadcast: 0)\n",
      "2024-03-13 00:04:41.362 (   4.930s) [            9D67]      netinterfaces.cpp:105   INFO| \tIPv6 addr: fe80::ef63:bf2d:f587:a8de%utun3\n",
      "2024-03-13 00:04:41.362 (   4.930s) [            9D67]      netinterfaces.cpp:91    INFO| netif 'utun4' (status: 1, multicast: 32768, broadcast: 0)\n",
      "2024-03-13 00:04:41.362 (   4.930s) [            9D67]      netinterfaces.cpp:91    INFO| netif 'utun4' (status: 1, multicast: 32768, broadcast: 0)\n",
      "2024-03-13 00:04:41.362 (   4.930s) [            9D67]      netinterfaces.cpp:105   INFO| \tIPv6 addr: fe80::532d:231c:d6ca:f267%utun4\n",
      "2024-03-13 00:04:41.362 (   4.930s) [            9D67]         api_config.cpp:270   INFO| Loaded default config\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Try resolving the EEG stream.\n",
    "print(\"Looking for an EEG stream...\")\n",
    "streams = resolve_stream('type', 'EEG')\n",
    "\n",
    "# Assuming numpy is already imported.\n",
    "# Assuming you have access to the inlet after resolving the stream.\n",
    "inlet = StreamInlet(streams[0])\n",
    "\n",
    "# Function to collect a single chunk.\n",
    "def collect_one_chunk(inlet):\n",
    "    while True:\n",
    "        # Attempt to pull a chunk from the stream.\n",
    "        chunk, timestamps = inlet.pull_chunk()\n",
    "\n",
    "        if chunk:\n",
    "            # If a chunk is received, save it and exit the function.\n",
    "            print(f\"Received chunk with timestamps: {timestamps[0]} to {timestamps[-1]}\")\n",
    "            np.save('chunk.npy', chunk)  # Ensure numpy is imported.\n",
    "            print(\"Chunk saved.\")\n",
    "            break  # Exit the loop after saving the chunk.\n",
    "\n",
    "# Call the function to start collecting.\n",
    "collect_one_chunk(inlet)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Configuration\n",
    "srate = 160  # Sampling rate of the EEG data, adjust as needed\n",
    "epoch_length_sec = 5  # Length of the desired sample in seconds\n",
    "samples_needed = srate * epoch_length_sec  # Number of samples needed for ~5 seconds\n",
    "\n",
    "print(\"Looking for an EEG stream...\")\n",
    "streams = resolve_stream('type', 'EEG')\n",
    "inlet = StreamInlet(streams[0])\n",
    "\n",
    "def collect_and_save_single_sample(inlet, samples_needed):\n",
    "    buffer = []  # Initialize the buffer to hold collected samples\n",
    "    timestamps = []  # To store timestamps of each sample\n",
    "\n",
    "    while len(buffer) < samples_needed:\n",
    "        # Continuously pull samples\n",
    "        sample, timestamp = inlet.pull_sample()\n",
    "        if sample:\n",
    "            buffer.append(sample)  # Add the sample to the buffer\n",
    "            timestamps.append(timestamp)  # Add the timestamp\n",
    "\n",
    "        if len(buffer) >= samples_needed:\n",
    "            # Once we have enough samples, save and exit\n",
    "            np.save('sample.npy', np.array(buffer))  # Save the buffer as a numpy file\n",
    "            print(f\"Saved ~{epoch_length_sec}-second sample with {len(buffer)} samples.\")\n",
    "            return  # Exit the function, effectively stopping data collection\n",
    "\n",
    "# Call the function to collect, save, and then stop\n",
    "collect_and_save_single_sample(inlet, samples_needed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(\"Looking for an EEG stream...\")\n",
    "streams = resolve_stream('type', 'EEG')\n",
    "inlet = StreamInlet(streams[0])\n",
    "\n",
    "def collect_and_save_single_sample(inlet, samples_needed):\n",
    "    '''\n",
    "    Test function to collect and save a single sample of EEG data\n",
    "\n",
    "    :param inlet: The LSL StreamInlet object\n",
    "    :param samples_needed: The number of samples to collect\n",
    "    :return: None\n",
    "    '''\n",
    "    buffer = []  # Initialize the buffer to hold collected samples\n",
    "    timestamps = []  # To store timestamps of each sample\n",
    "\n",
    "    while len(buffer) < samples_needed:\n",
    "        # Continuously pull samples\n",
    "        sample, timestamp = inlet.pull_sample()\n",
    "        if sample:\n",
    "            buffer.append(sample)  # Add the sample to the buffer\n",
    "            timestamps.append(timestamp)  # Add the timestamp\n",
    "\n",
    "        if len(buffer) >= samples_needed:\n",
    "            # Once we have enough samples, save and exit\n",
    "            np.save('sample.npy', np.array(buffer))  # Save the buffer as a numpy file\n",
    "            print(f\"Saved ~{epoch_length_sec}-second sample with {len(buffer)} samples.\")\n",
    "            return  # Exit the function, effectively stopping data collection\n",
    "\n",
    "# Call the function to collect, save, and then stop\n",
    "collect_and_save_single_sample(inlet, samples_needed)\n",
    "sys.exit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Test with one saved sample sent \n",
    "sample = np.load('sample.npy')\n",
    "sample.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed_data = preprocess_single_trial(sample, srate, channel_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# csp + lda decode\n",
    "model_path = os.path.join(models_dir, 'csp_lda.pkl')\n",
    "loaded_model = joblib.load(model_path)\n",
    "predicted_labels = loaded_model.predict(preprocessed_data)\n",
    "predicted_labels\n",
    "\n",
    "# Save result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# csp + logistic regression decode\n",
    "model_path = os.path.join(models_dir, 'csp_logistic.pkl')\n",
    "loaded_model = joblib.load(model_path)\n",
    "predicted_labels = loaded_model.predict(preprocessed_data)\n",
    "predicted_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# csp + svm decode\n",
    "model_path = os.path.join(models_dir, 'csp_svm.pkl')\n",
    "loaded_model = joblib.load(model_path)\n",
    "predicted_labels = loaded_model.predict(preprocessed_data)\n",
    "predicted_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, n_chans, n_times = preprocessed_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# eeg_conformer decode\n",
    "model = EEGConformer(\n",
    "    n_outputs= 2,\n",
    "    n_chans = n_chans,\n",
    "    sfreq= srate,\n",
    "    n_times = n_times,\n",
    "    n_filters_time=40, \n",
    "    filter_time_length=25,\n",
    "    pool_time_length=75,\n",
    "    pool_time_stride=15,\n",
    "    drop_prob=0.7,\n",
    "    att_depth=3,\n",
    "    att_heads=10,\n",
    "    att_drop_prob=0.7,\n",
    "    final_fc_length='auto', # could be 'auto' or int\n",
    "    return_features=False, # returns the features before the last classification layer if True\n",
    "    chs_info=None,\n",
    "    input_window_seconds=None,\n",
    "    add_log_softmax=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model = os.path.join(models_dir, 'cross_subject_conformer.pth')\n",
    "checkpoint = torch.load(loaded_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def online_decode(inlet, samples_per_epoch, loaded_model, srate, channel_names, results_dir):\n",
    "    \"\"\"\n",
    "    Continuously pull samples from the LSL stream and decode them.\n",
    "    \"\"\"\n",
    "    buffer = []  # Initialize buffer for accumulating samples\n",
    "    pred_hist = []  # History of predictions\n",
    "\n",
    "    while True:\n",
    "        # Pull sample from LSL stream\n",
    "        sample, timestamp = inlet.pull_sample()\n",
    "        if sample:  # Ensure sample is not None\n",
    "            buffer.append(sample)\n",
    "\n",
    "        # Check if buffer has enough samples to form an epoch\n",
    "        if len(buffer) >= samples_per_epoch:\n",
    "            epoch = np.array(buffer[:samples_per_epoch])\n",
    "            buffer = buffer[samples_per_epoch:]  # Remove the processed samples from the buffer\n",
    "\n",
    "            # Decode the epoch\n",
    "            prediction = decode_sample(epoch, loaded_model, srate, channel_names)\n",
    "            pred_hist.append((timestamp, prediction))  # Append the prediction and its timestamp to the history\n",
    "            print(f\"Timestamp: {timestamp}, Prediction: {prediction}\")\n",
    "\n",
    "        # Condition to stop after decoding 3 epochs\n",
    "        if len(pred_hist) >= 3:\n",
    "            # Save the results and exit the loop\n",
    "            np.save(os.path.join(results_dir, 'results.npy'), np.array(pred_hist))\n",
    "            print(\"Saved 3 epochs and their predictions.\")\n",
    "            break  # Exit the while loop\n",
    "\n",
    "def decode_sample(epoch, loaded_model, srate, channel_names):\n",
    "    \"\"\"\n",
    "    Process and decode an epoch of EEG data.\n",
    "    \"\"\"\n",
    "    preprocessed_epoch = preprocess_single_trial(epoch, srate, channel_names)  # Ensure this function exists and works as intended\n",
    "    prediction = loaded_model.predict(preprocessed_epoch)  # Fixed to use the correct variable\n",
    "    return prediction\n",
    "\n",
    "# Example of calling online_decode (make sure all the required variables are defined)\n",
    "# online_decode(inlet, samples_per_epoch, loaded_model, srate, channel_names, results_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = os.path.join(models_dir, 'csp_logistic.pkl')\n",
    "loaded_model = joblib.load(model_path)\n",
    "\n",
    "print(\"Looking for an EEG stream...\")\n",
    "streams = resolve_stream('type', 'EEG')\n",
    "online_decode(inlet, samples_per_epoch, loaded_model, srate, channel_names, results_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples_per_epoch = srate * epoch_length_sec\n",
    "\n",
    "# Resolve the stream\n",
    "print(\"Looking for an EEG stream...\")\n",
    "streams = resolve_stream('type', 'EEG', 'name', 'BioSemi')\n",
    "#inlet = StreamInlet(streams[0])\n",
    "\n",
    "# Initialize a buffer for accumulating samples\n",
    "buffer = []\n",
    "\n",
    "model_path = os.path.join(models_dir, 'csp_logistic.pkl')\n",
    "loaded_model = joblib.load(model_path)\n",
    "\n",
    "def decode_sample(epoch, loaded_model, srate, channel_names):\n",
    "    \"\"\"\n",
    "    Process and decode an epoch of EEG data.\n",
    "    \"\"\"\n",
    "    preprocessed_epoch = preprocess_single_trial(epoch, srate, channel_names)\n",
    "    predicted_labels = loaded_model.predict(preprocessed_data)\n",
    "    return prediction\n",
    "\n",
    "def online_decode(inlet):\n",
    "    \"\"\"\n",
    "    Continuously pull samples from the LSL stream and decode them.\n",
    "    \"\"\"\n",
    "    pred_hist = []\n",
    "    while True:\n",
    "        # Pull sample from LSL stream\n",
    "        sample, timestamp = inlet.pull_sample()\n",
    "        buffer.append(sample)\n",
    "        \n",
    "        # Check if buffer has enough samples to form an epoch\n",
    "        if len(buffer) >= samples_per_epoch:\n",
    "            epoch = np.array(buffer[:samples_per_epoch])  \n",
    "            buffer = buffer[samples_per_epoch:]  \n",
    "            \n",
    "            # Decode the epoch\n",
    "            prediction = decode_sample(epoch, loaded_model, srate, channel_names)\n",
    "            pred_hist.append((timestamp, prediction))\n",
    "            print(f\"Timestamp: {timestamp}, Prediction: {prediction}\")\n",
    "\n",
    "        if len(pred_hist) >= 3:\n",
    "            # Save the results\n",
    "            np.save(os.path.join(results_dir, 'results.npy'), np.array(pred_hist))\n",
    "            return\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "eeg_decoder",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
