{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pylsl import StreamInlet, resolve_stream\n",
    "import numpy as np\n",
    "import joblib  # Used for loading sklearn models\n",
    "import sys\n",
    "import os\n",
    "import json\n",
    "#import torch\n",
    "\n",
    "sys.path.append('./src/processing')\n",
    "from preprocessing import *\n",
    "\n",
    "sys.path.append('./models')\n",
    "from eegconformer import EEGConformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_dir = './models/trained/'\n",
    "results_dir = './results/'\n",
    "\n",
    "# Configuration\n",
    "srate = 160  #Sampling rate of the EEG data\n",
    "epoch_length_sec = 5  # Length of the desired sample in seconds\n",
    "samples_needed = srate * epoch_length_sec  # Number of samples needed for ~5 seconds\n",
    "# Manually define from eegbci dataset\n",
    "channel_names = ['FC5', 'FC3', 'FC1', 'FCz', 'FC2', 'FC4', 'FC6', 'C5', 'C3', 'C1', 'Cz', 'C2', 'C4', 'C6', 'CP5', 'CP3', 'CP1', 'CPz', 'CP2', 'CP4', 'CP6', 'Fp1', 'Fpz', 'Fp2', 'AF7', 'AF3', 'AFz', 'AF4', 'AF8', 'F7', 'F5', 'F3', 'F1', 'Fz', 'F2', 'F4', 'F6', 'F8', 'FT7', 'FT8', 'T7', 'T8', 'T9', 'T10', 'TP7', 'TP8', 'P7', 'P5', 'P3', 'P1', 'Pz', 'P2', 'P4', 'P6', 'P8', 'PO7', 'PO3', 'POz', 'PO4', 'PO8', 'O1', 'Oz', 'O2', 'Iz']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Configuration\n",
    "srate = 160  # Sampling rate of the EEG data, adjust as needed\n",
    "epoch_length_sec = 5  # Length of the desired sample in seconds\n",
    "samples_needed = srate * epoch_length_sec  # Number of samples needed for ~5 seconds\n",
    "\n",
    "print(\"Looking for an EEG stream...\")\n",
    "streams = resolve_stream('type', 'EEG')\n",
    "inlet = StreamInlet(streams[0])\n",
    "\n",
    "def collect_and_save_single_sample(inlet, samples_needed):\n",
    "    buffer = []  # Initialize the buffer to hold collected samples\n",
    "    timestamps = []  # To store timestamps of each sample\n",
    "\n",
    "    while len(buffer) < samples_needed:\n",
    "        # Continuously pull samples\n",
    "        sample, timestamp = inlet.pull_sample()\n",
    "        if sample:\n",
    "            buffer.append(sample)  # Add the sample to the buffer\n",
    "            timestamps.append(timestamp)  # Add the timestamp\n",
    "\n",
    "        if len(buffer) >= samples_needed:\n",
    "            # Once we have enough samples, save and exit\n",
    "            np.save('sample.npy', np.array(buffer))  # Save the buffer as a numpy file\n",
    "            print(f\"Saved ~{epoch_length_sec}-second sample with {len(buffer)} samples.\")\n",
    "            return  # Exit the function, effectively stopping data collection\n",
    "\n",
    "# Call the function to collect, save, and then stop\n",
    "collect_and_save_single_sample(inlet, samples_needed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(800, 64)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # Test with one saved sample sent \n",
    "sample = np.load('sample.npy')\n",
    "sample.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed_data = preprocess_single_trial(sample, srate, channel_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# csp + lda decode\n",
    "model_path = os.path.join(models_dir, 'csp_lda.pkl')\n",
    "loaded_model = joblib.load(model_path)\n",
    "predicted_labels = loaded_model.predict(preprocessed_data)\n",
    "predicted_labels\n",
    "\n",
    "# Save result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# csp + logistic regression decode\n",
    "model_path = os.path.join(models_dir, 'csp_logistic.pkl')\n",
    "loaded_model = joblib.load(model_path)\n",
    "predicted_labels = loaded_model.predict(preprocessed_data)\n",
    "predicted_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# csp + svm decode\n",
    "model_path = os.path.join(models_dir, 'csp_svm.pkl')\n",
    "loaded_model = joblib.load(model_path)\n",
    "predicted_labels = loaded_model.predict(preprocessed_data)\n",
    "predicted_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, n_chans, n_times = preprocessed_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# eeg_conformer decode\n",
    "model = EEGConformer(\n",
    "    n_outputs= 2,\n",
    "    n_chans = n_chans,\n",
    "    sfreq= srate,\n",
    "    n_times = n_times,\n",
    "    n_filters_time=40, \n",
    "    filter_time_length=25,\n",
    "    pool_time_length=75,\n",
    "    pool_time_stride=15,\n",
    "    drop_prob=0.7,\n",
    "    att_depth=3,\n",
    "    att_heads=10,\n",
    "    att_drop_prob=0.7,\n",
    "    final_fc_length='auto', # could be 'auto' or int\n",
    "    return_features=False, # returns the features before the last classification layer if True\n",
    "    chs_info=None,\n",
    "    input_window_seconds=None,\n",
    "    add_log_softmax=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model = os.path.join(models_dir, 'cross_subject_conformer.pth')\n",
    "checkpoint = torch.load(loaded_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import json\n",
    "import os\n",
    "\n",
    "def online_decode(inlet, samples_per_epoch, loaded_model, srate, channel_names, results_dir):\n",
    "    buffer = []  # Initialize buffer for accumulating samples\n",
    "    pred_hist = []  # History of predictions\n",
    "\n",
    "    while True:\n",
    "        sample, timestamp = inlet.pull_sample()\n",
    "        if sample:\n",
    "            buffer.append(sample)\n",
    "\n",
    "        if len(buffer) >= samples_per_epoch:\n",
    "            epoch = np.array(buffer[:samples_per_epoch])\n",
    "            buffer = buffer[samples_per_epoch:]\n",
    "\n",
    "            prediction = decode_sample(epoch, loaded_model, srate, channel_names)\n",
    "            # Convert the prediction to a list if it's a numpy array\n",
    "            if isinstance(prediction, np.ndarray):\n",
    "                prediction = prediction.tolist()\n",
    "            pred_hist.append(prediction)\n",
    "\n",
    "            print(f\"Timestamp: {timestamp}, Prediction: {prediction}\")\n",
    "\n",
    "        if len(pred_hist) >= 3:\n",
    "            # Convert the entire history to a format that's JSON serializable\n",
    "            data_to_save = json.dumps(pred_hist, default=lambda o: o.tolist() if isinstance(o, np.ndarray) else o)\n",
    "\n",
    "            with open(os.path.join(results_dir, 'results.txt'), 'w') as file:\n",
    "                file.write(data_to_save)\n",
    "                \n",
    "            print(\"Saved 3 epochs and their predictions.\")\n",
    "            break\n",
    "\n",
    "def decode_sample(epoch, loaded_model, srate, channel_names):\n",
    "    preprocessed_epoch = preprocess_single_trial(epoch, srate, channel_names)  # Assume this function is defined elsewhere\n",
    "    prediction = loaded_model.predict(preprocessed_epoch)\n",
    "    return prediction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking for an EEG stream...\n",
      "Creating RawArray with float64 data, n_channels=64, n_times=800\n",
      "    Range : 0 ... 799 =      0.000 ...     4.994 secs\n",
      "Ready.\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 7 - 30 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 7.00\n",
      "- Lower transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 6.00 Hz)\n",
      "- Upper passband edge: 30.00 Hz\n",
      "- Upper transition bandwidth: 7.50 Hz (-6 dB cutoff frequency: 33.75 Hz)\n",
      "- Filter length: 265 samples (1.656 s)\n",
      "\n",
      "Timestamp: 167079.8842762, Prediction: [0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating RawArray with float64 data, n_channels=64, n_times=800\n",
      "    Range : 0 ... 799 =      0.000 ...     4.994 secs\n",
      "Ready.\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 7 - 30 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 7.00\n",
      "- Lower transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 6.00 Hz)\n",
      "- Upper passband edge: 30.00 Hz\n",
      "- Upper transition bandwidth: 7.50 Hz (-6 dB cutoff frequency: 33.75 Hz)\n",
      "- Filter length: 265 samples (1.656 s)\n",
      "\n",
      "Timestamp: 167084.8808496, Prediction: [1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating RawArray with float64 data, n_channels=64, n_times=800\n",
      "    Range : 0 ... 799 =      0.000 ...     4.994 secs\n",
      "Ready.\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 7 - 30 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 7.00\n",
      "- Lower transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 6.00 Hz)\n",
      "- Upper passband edge: 30.00 Hz\n",
      "- Upper transition bandwidth: 7.50 Hz (-6 dB cutoff frequency: 33.75 Hz)\n",
      "- Filter length: 265 samples (1.656 s)\n",
      "\n",
      "Timestamp: 167089.8904504, Prediction: [1]\n",
      "Saved 3 epochs and their predictions.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.0s\n"
     ]
    }
   ],
   "source": [
    "model_path = os.path.join(models_dir, 'csp_logistic.pkl')\n",
    "loaded_model = joblib.load(model_path)\n",
    "\n",
    "print(\"Looking for an EEG stream...\")\n",
    "streams = resolve_stream('type', 'EEG')\n",
    "inlet = StreamInlet(streams[0])\n",
    "online_decode(inlet, samples_needed, loaded_model, srate, channel_names, results_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples_per_epoch = srate * epoch_length_sec\n",
    "\n",
    "# Resolve the stream\n",
    "print(\"Looking for an EEG stream...\")\n",
    "streams = resolve_stream('type', 'EEG', 'name', 'BioSemi')\n",
    "#inlet = StreamInlet(streams[0])\n",
    "\n",
    "# Initialize a buffer for accumulating samples\n",
    "buffer = []\n",
    "\n",
    "model_path = os.path.join(models_dir, 'csp_logistic.pkl')\n",
    "loaded_model = joblib.load(model_path)\n",
    "\n",
    "def decode_sample(epoch, loaded_model, srate, channel_names):\n",
    "    \"\"\"\n",
    "    Process and decode an epoch of EEG data.\n",
    "    \"\"\"\n",
    "    preprocessed_epoch = preprocess_single_trial(epoch, srate, channel_names)\n",
    "    predicted_labels = loaded_model.predict(preprocessed_data)\n",
    "    return prediction\n",
    "\n",
    "def online_decode(inlet):\n",
    "    \"\"\"\n",
    "    Continuously pull samples from the LSL stream and decode them.\n",
    "    \"\"\"\n",
    "    pred_hist = []\n",
    "    while True:\n",
    "        # Pull sample from LSL stream\n",
    "        sample, timestamp = inlet.pull_sample()\n",
    "        buffer.append(sample)\n",
    "        \n",
    "        # Check if buffer has enough samples to form an epoch\n",
    "        if len(buffer) >= samples_per_epoch:\n",
    "            epoch = np.array(buffer[:samples_per_epoch])  \n",
    "            buffer = buffer[samples_per_epoch:]  \n",
    "            \n",
    "            # Decode the epoch\n",
    "            prediction = decode_sample(epoch, loaded_model, srate, channel_names)\n",
    "            pred_hist.append((timestamp, prediction))\n",
    "            print(f\"Timestamp: {timestamp}, Prediction: {prediction}\")\n",
    "\n",
    "        if len(pred_hist) >= 3:\n",
    "            # Save the results\n",
    "            np.save(os.path.join(results_dir, 'results.npy'), np.array(pred_hist))\n",
    "            return\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "eeg_decoder",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
